# GOMI â™»ï¸ â€“ Projet CloudVision

GOMI est une application web fullstack permettant de :

- Trier des dÃ©chets grÃ¢ce Ã  une IA de classification dâ€™image.
- GÃ©nÃ©rer des recettes avec les ingrÃ©dients de son frigo grÃ¢ce Ã  une IA.
- GÃ©rer des utilisateurs (authentification et db).
- Proposer une interface fluide en React pour utiliser tous les services.

---

## ğŸ“ Structure du projet

Ce repository principal utilise des **submodules Git** pour organiser le code :

```bash
.
â”œâ”€â”€ client/           # Interface React (Frontend)
â”œâ”€â”€ server/           # API Flask (Backend + Auth)
â”œâ”€â”€ AI/
â”‚   â”œâ”€â”€ ai-trie/      # App Gradio IA de tri des dÃ©chets
â”‚   â””â”€â”€ ai-recipeV2/  # App Gradio IA de d'identification d'ingrÃ©dients et de generation d'une recette
    â””â”€â”€ ai-recipe-ollama/  #V1 de l'ia pour generation de la recette (Flask + Ollama)
```

âš ï¸ Tous les submodules doivent Ãªtre initialisÃ©s aprÃ¨s un clone :
```bash
git clone --recurse-submodules https://github.com/arthurGuillemin/Gomi.git
```
## ğŸ“¦ Submodules Hugging Face

Les projets IA sont des submodules Git, mÃªme sâ€™ils sont hÃ©bergÃ©s sur Hugging Face :

- [`ia/ai-trie`](https://huggingface.co/spaces/ankz22/trash-classifier/tree/main)
- [`ia/ai-recipe`](https://huggingface.co/spaces/ankz22/Fridge_recipe_app2/tree/main)

> **Note :** GitHub ne crÃ©e pas de lien cliquable automatiquement pour ces submodules, car Hugging Face nâ€™est pas reconnu comme un provider Git natif.

---

## ğŸŒ DÃ©ploiement

- ğŸŒ **App principale** (frontend) : [Netlify](https://gomiproject.netlify.app/)
- ğŸ§  **IA tri des dÃ©chets** (Gradio) : [Hugging Face](https://huggingface.co/spaces/ankz22/trash-classifier)
- ğŸ³ **IA recettes** (Gradio) : [Hugging Face](https://huggingface.co/spaces/ankz22/Fridge_recipe_app2)
- ğŸ—„ï¸ **Backend** : [Azure Web App](https://flask-backend-gomi-hbbjbyc9agend4fh.francecentral-01.azurewebsites.net)

---

---

## ğŸš€ Lancement (optionnel)

L'application est **dÃ©jÃ  dÃ©ployÃ©e**. Le lancement local nâ€™est **pas oblgatoire**.

### PrÃ©-requis

- Node.js (Frontend)
- Python 3.11+ (Backend + IA)
- `pip` & `venv`
- Docker (si utilisÃ©)
- **Fichier `.env` requis dans le backend pour utiliser Supabase** (non fourni pour des raisons de sÃ©curitÃ©)

### Lancer manuellement

```bash
# Frontend
cd client
npm install
npm run dev
```

```bash
# Backend
cd server/server
python -m venv .venv
source .venv/bin/activate  # (ou .venv\Scripts\activate sur Windows)
pip install -r ../requirements.txt
python run.py
```

```bash
# IA - tri des dÃ©chets
cd AI/ai-trie
python app.py
```

```bash
# IA - gÃ©nÃ©ration de recette
cd AI/ai-recipe
python app.py
```

```bash
# IA - gÃ©nÃ©ration de recette - Ollama
cd AI/ai-recipe-Ollama
pip install -r requirements.txt
ollama run llava
python app.py
```

---

## ğŸ“š Techs utilisÃ©es

- **Frontend** : React, Vite
- **Backend** : Flask, Gunicorn, Supabase ,  Werkzeug , marshmallow, pytest 
- **IA** : Gradio, Transformers , torch , torchvision , pillow , ollama
- **DevOps** : Docker, Github Actions , Git Submodules, Hugging Face Spaces, netlify , Azure

---


## ğŸ‘¨â€ğŸ’» Auteurs

Arthur Guillemin â€“ [Hugging Face](https://huggingface.co/ankz22)
Kelly Gama - [Github](https://github.com/yelineeee)
Emilie Caverne [Github](https://github.com/emilie-caverne)
Ryan Annic [Github](https://github.com/gladiaaa)
