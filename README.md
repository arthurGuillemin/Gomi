# GOMI â™»ï¸ â€“ Projet CloudVision

GOMI est une application web fullstack permettant de :

- Trier des dÃ©chets grÃ¢ce Ã  une IA de classification dâ€™image.
- GÃ©nÃ©rer des recettes avec les ingrÃ©dients de son frigo grÃ¢ce Ã  une IA.
- GÃ©rer des utilisateurs (authentification et db).
- Proposer une interface fluide en React pour utiliser tous les services.

---

## ğŸ—ï¸ Architecture & Infrastructure


### ğŸ“ Structure du projet

Ce repository principal utilise des **submodules Git** pour organiser le code :

```bash
.
â”œâ”€â”€ client/           # Interface React (Frontend)
â”œâ”€â”€ server/           # API Flask (Backend + Auth)
â”œâ”€â”€ AI/
â”‚   â”œâ”€â”€ ai-trie/      # App Gradio IA de tri des dÃ©chets
â”‚   â””â”€â”€ ai-recipeV2/  # App Gradio IA de d'identification d'ingrÃ©dients et de generation d'une recette
    â””â”€â”€ ai-recipe-ollama/  #V1 de l'ia pour generation de la recette (Flask + Ollama)
```

### ğŸ“¦ Submodules Hugging Face

Les projets IA sont des submodules Git, mÃªme sâ€™ils sont hÃ©bergÃ©s sur Hugging Face :

- [`AI/ai-trie`](https://huggingface.co/spaces/ankz22/trash-classifier/tree/main)
- [`AI/ai-recipe`](https://huggingface.co/spaces/ankz22/Fridge_recipe_app2/tree/main)

> **Note :** GitHub ne crÃ©e pas de lien cliquable automatiquement pour ces submodules, car Hugging Face nâ€™est pas reconnu comme un provider Git natif.

---
### âš™ï¸ IntÃ©gration continue (CI)

#### Frontend (`client/`)

![Frontend CI](https://github.com/arthurGuillemin/GomiFrontend/actions/workflows/react-ci.yml/badge.svg)

Utilise **GitHub Actions** pour :

- VÃ©rifier le code avec `eslint`
- Construire le projet (`npm run build`)

#### Backend (`server/`)

![Backend CI](https://github.com/arthurGuillemin/GomiBackend/actions/workflows/docker-push.yml/badge.svg)

GitHub Actions automatise :

- Lâ€™installation des dÃ©pendances Python
- Lâ€™exÃ©cution des tests unitaires (`pytest`)
- Le build et le push de lâ€™image Docker vers Docker Hub

 Les secrets (ex : SUPABASE, JWT) sont stockÃ©s de faÃ§on sÃ©curisÃ©e via **GitHub Secrets**.

---


### ğŸ³ Conteneurisation & Orchestration

- Le backend Flask est conteneurisÃ© via un **Dockerfile**.
- Un **docker-compose.yml** orchestre :
  - Le serveur Flask
  - Un reverse proxy **Nginx**
- Lâ€™image backend est automatiquement pushÃ©e sur [Docker Hub](https://hub.docker.com/r/arthurguill/flask-backend-gomi) Ã  chaque push sur `main`.

---

### ğŸ“„ Documentation API

- Documentation Swagger gÃ©nÃ©rÃ©e automatiquement avec **Flasgger**
- Accessible via `/apidocs` (en local ou en prod)

---

### ğŸŒ DÃ©ploiement

- ğŸŒ **App principale** (frontend) : [Netlify](https://gomiproject.netlify.app/)  [![Status](https://api.netlify.com/api/v1/badges/1de4ad27-8826-4111-b733-ca72787f7b4d/deploy-status)](https://app.netlify.com/projects/gomiproject/deploys)
- ğŸ§  **IA tri des dÃ©chets** (Gradio) : [Hugging Face](https://huggingface.co/spaces/ankz22/trash-classifier)
- ğŸ³ **IA recettes** (Gradio) : [Hugging Face](https://huggingface.co/spaces/ankz22/Fridge_recipe_app2)
- ğŸ—„ï¸ **Backend** : [Azure Web App](https://flask-backend-gomi-hbbjbyc9agend4fh.francecentral-01.azurewebsites.net)

---
âš ï¸ Tous les submodules doivent Ãªtre initialisÃ©s aprÃ¨s un clone :
```bash
git clone --recurse-submodules https://github.com/arthurGuillemin/Gomi.git
```
---

## ğŸš€ Lancement (optionnel)

L'application est **dÃ©jÃ  dÃ©ployÃ©e**. Le lancement local nâ€™est **pas oblgatoire**.

### PrÃ©-requis

- Node.js (Frontend)
- Python 3.11+ (Backend + IA)
- `pip` & `venv`
- Docker (si utilisÃ©)
- **Fichier `.env` requis dans le backend pour utiliser Supabase** (non fourni pour des raisons de sÃ©curitÃ©)

### Lancer manuellement

```bash
# Frontend
cd client
npm install
npm run dev
```

```bash
# Backend
cd server/server
python -m venv .venv
source .venv/bin/activate  # (ou .venv\Scripts\activate sur Windows)
pip install -r ../requirements.txt
python run.py
```

```bash
# IA - tri des dÃ©chets
cd AI/ai-trie
python app.py
```

```bash
# IA - gÃ©nÃ©ration de recette
cd AI/ai-recipe
python app.py
```

```bash
# IA - gÃ©nÃ©ration de recette - Ollama
cd AI/ai-recipe-Ollama
pip install -r requirements.txt
ollama run llava
python app.py
```

---

### ğŸ“š Techs utilisÃ©es

- **Frontend** : React, Vite , vite-plugin-pwa
- **Backend** : Flask, Gunicorn, Supabase ,  Werkzeug , marshmallow, pytest 
- **IA** : Gradio, Transformers , torch , torchvision , pillow , ollama
- **DevOps** : Docker, Github Actions , Git Submodules, Hugging Face Spaces, netlify , Azure

---


### ğŸ‘¨â€ğŸ’» Auteurs

Arthur Guillemin â€“ [Hugging Face](https://huggingface.co/ankz22)  --  Kelly Gama - [Github](https://github.com/yelineeee)  --  Emilie Caverne - [Github](https://github.com/emilie-caverne)  --  Ryan Annic - [Github](https://github.com/gladiaaa)
